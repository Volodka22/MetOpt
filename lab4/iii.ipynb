{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iii.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1055,
      "metadata": {
        "id": "lIUgscqfFMQC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from math import *\n",
        "from scipy.optimize import minimize, least_squares\n",
        "from autograd import grad, jacobian\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy import linalg as LA\n",
        "from abc import abstractmethod\n",
        "from numpy import matmul\n",
        "import scipy\n",
        "import scipy.optimize\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#scipy.optimize.leas_squares"
      ],
      "metadata": {
        "id": "okoyzV6xztqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rosenbrock(x):\n",
        "    return (1 - x[0])**2 + 100 * (x[1] - x[0]**2)**2\n",
        "\n",
        "def hess(f):\n",
        "    J = jacobian(f)\n",
        "    return 2 * J.T * J\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "dQqpR6HTGjlc"
      },
      "execution_count": 1056,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Gradient"
      ],
      "metadata": {
        "id": "gYWQvUzu05a-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_x = [100., -3.]\n",
        "print(\"sample\")\n",
        "print(minimize(rosenbrock, start_x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xgHZYCYsyEA",
        "outputId": "66bbf231-3985-4f68-edba-c49f267b8045"
      },
      "execution_count": 1057,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample\n",
            "      fun: 2.0053198675217142e-11\n",
            " hess_inv: array([[0.49981597, 0.99962823],\n",
            "       [0.99962823, 2.00424885]])\n",
            "      jac: array([-3.40882358e-09,  2.00843786e-09])\n",
            "  message: 'Optimization terminated successfully.'\n",
            "     nfev: 1988\n",
            "      nit: 386\n",
            "     njev: 497\n",
            "   status: 0\n",
            "  success: True\n",
            "        x: array([0.99999552, 0.99999104])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rosenbrock_with_grad(x):\n",
        "    x = torch.tensor(x, requires_grad=True)\n",
        "    res = rosenbrock(x)\n",
        "    res.backward()\n",
        "    return res.data.cpu().numpy(), x.grad.data.cpu().numpy()\n",
        "\n",
        "print(\"with gradient\")\n",
        "print(minimize(rosenbrock_with_grad, start_x, jac=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjLsEBL11LTk",
        "outputId": "5d0fa51a-bc33-4c87-cbef-f7378748ec24"
      },
      "execution_count": 1058,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with gradient\n",
            "      fun: 6.781861341369393e-15\n",
            " hess_inv: array([[0.49939138, 0.99896245],\n",
            "       [0.99896245, 2.0032524 ]])\n",
            "      jac: array([ 3.03316488e-06, -1.48049657e-06])\n",
            "  message: 'Optimization terminated successfully.'\n",
            "     nfev: 492\n",
            "      nit: 384\n",
            "     njev: 492\n",
            "   status: 0\n",
            "  success: True\n",
            "        x: array([1.00000004, 1.00000006])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"with bounds\")\n",
        "print(minimize(rosenbrock, start_x, bounds = ((13, None), (-5, -2))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yE2Nzm2YuQEa",
        "outputId": "435d9470-61e9-4bc7-83bb-9432ebea2bba"
      },
      "execution_count": 1059,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "with bounds\n",
            "      fun: 2924244.0\n",
            " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
            "      jac: array([889224.09340739, -34200.02758503])\n",
            "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
            "     nfev: 30\n",
            "      nit: 8\n",
            "   status: 0\n",
            "  success: True\n",
            "        x: array([13., -2.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare"
      ],
      "metadata": {
        "id": "5rl385uCFi-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MatrixSolver:\n",
        "    # compute gradinent of function f in point x with step h\n",
        "    @staticmethod\n",
        "    def grad(x, f, eps):\n",
        "        derivative = np.zeros(np.size(x))\n",
        "        for i in range(np.size(x)):\n",
        "            x[i] += eps\n",
        "            f1 = f(x)\n",
        "            x[i] -= 2 * eps\n",
        "            f2 = f(x)\n",
        "            x[i] += eps\n",
        "            derivative[i] = (f1 - f2) / (2 * eps)\n",
        "        return derivative\n",
        "\n",
        "    # compute Jacobian of functions rs = (r_1...r_n), r_i = r_i(x_1...x_m)\n",
        "    @staticmethod\n",
        "    def findJacobian(rs, x, eps):\n",
        "        n = np.size(rs)\n",
        "        m = np.size(x)\n",
        "        J = np.zeros((n, m))\n",
        "        for i in range(n):\n",
        "            J[i] = MatrixSolver.grad(x, rs[i], eps)\n",
        "\n",
        "        return J\n",
        "\n",
        "    # compute pseudo inverse of matrix X\n",
        "    @staticmethod\n",
        "    def pseudoInverse(x):\n",
        "        return np.linalg.inv(x.T @ x) @ x.T\n",
        "\n",
        "    # compute hessian of functions R^n -> R\n",
        "    @staticmethod\n",
        "    def findHessian(func, x, eps):\n",
        "        J = MatrixSolver.findJacobian(func, x, eps)\n",
        "        return 2 * J.T @ J"
      ],
      "metadata": {
        "id": "EddPxtvdGIhw"
      },
      "execution_count": 1060,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Searcher:\n",
        "    def __init__(self, eps, max_iterations, func, start_x):\n",
        "        self.eps = eps\n",
        "        self.max_iterations = max_iterations\n",
        "        self.func = func\n",
        "        self.start_x = start_x\n",
        "\n",
        "    # stop method\n",
        "    def is_not_final(self):\n",
        "        return LA.norm(self.next - self.cur_x) > self.eps and self.max_iterations >= self.epoch\n",
        "\n",
        "    # draw plot\n",
        "    def draw(self):\n",
        "        # print(\"points:\", self.points)\n",
        "\n",
        "        min_point = self.points[-1]\n",
        "        print(\"minimum:\", min_point)\n",
        "        \n",
        "        repoints = np.asarray(self.points).reshape(-1, 2)\n",
        "        pic = plt.figure(figsize=(10, 10))\n",
        "        offset = max(np.max(repoints[:, 0]), abs(np.min(repoints[:, 0])))\n",
        "        xs = np.linspace(min_point[0] - offset, min_point[0] + offset, 1000)\n",
        "\n",
        "        plt.plot(xs, [self.func([x]) for x in xs])\n",
        "        plt.plot(repoints[:, 0], repoints[:, 1], 'o-', color=\"red\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def save_point(self, x):\n",
        "        self.points.append(np.append(x, self.func([x])))\n",
        "\n",
        "    # executor method\n",
        "    def run(self, drawing = 1):\n",
        "        self.epoch = 2\n",
        "        self.cur_x = self.start_x\n",
        "        self.points = list()\n",
        "        self.save_point(self.cur_x)\n",
        "    \n",
        "        self.next_point()\n",
        "        while (self.is_not_final()):\n",
        "            self.epoch += 1\n",
        "            self.cur_x = self.next\n",
        "            self.save_point(self.cur_x)\n",
        "            self.next_point()\n",
        "\n",
        "        self.save_point(self.next)\n",
        "        print(\"argmin: \", self.next, \"\\nepoches: \", self.epoch, \"\\nnfev: \", self.epoch * 2)\n",
        "\n",
        "        if drawing == 1:\n",
        "            self.draw()\n",
        "\n",
        "\n",
        "    # find next point\n",
        "    @abstractmethod\n",
        "    def next_point(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "cnCq1PsrHBCN"
      },
      "execution_count": 1061,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dogleg(Searcher):\n",
        "\n",
        "    def __init__(self, eps, max_iteration, func, start_x,\n",
        "                 initial_trust_radius=1.0, max_trust_radius=100.0, eta = 0.15):\n",
        "        super().__init__(eps, max_iteration, func, start_x)\n",
        "        self.initial_trust_radius = initial_trust_radius\n",
        "        self.max_trust_radius = max_trust_radius\n",
        "        self.eta = eta\n",
        "\n",
        "    def find_shift(self):\n",
        "        # find optimum\n",
        "        optimum = -(np.linalg.inv(self.hess) @ self.jac)\n",
        "        norm_opt = sqrt(optimum @ optimum)\n",
        "\n",
        "        if norm_opt <= self.trust_radius:\n",
        "            return optimum\n",
        "\n",
        "        # find Cauchy point\n",
        "        cauchy = - (self.jac @ self.jac / (self.jac @ (self.hess @ self.jac))) @ self.jac\n",
        "        norm_cauchy = sqrt(cauchy @ cauchy)\n",
        "\n",
        "        # stop in circul\n",
        "        if norm_cauchy >= self.trust_radius:\n",
        "            return self.trust_radius * cauchy / norm_cauchy\n",
        "\n",
        "        tau = (self.trust_radius - cauchy) / (optimum - cauchy)\n",
        "\n",
        "        return cauchy + tau * (optimum - cauchy)\n",
        "\n",
        "    def find_trust_radius(self, shift):\n",
        "        act_reduction = self.func(self.cur_x) - self.func(self.cur_x + shift)\n",
        "        pred_reduction = -(self.jac @ shift + 0.5 * (shift @ (self.hess @ shift)))\n",
        "\n",
        "        rho = act_reduction / pred_reduction\n",
        "        if pred_reduction == 0.0:\n",
        "            rho = 1e99\n",
        "\n",
        "        norm_shift = sqrt(shift @ shift)\n",
        "\n",
        "        if rho < 0.25:\n",
        "            self.trust_radius = 0.25 * norm_shift\n",
        "        else:\n",
        "            if rho > 0.75 and norm_shift == self.trust_radius:\n",
        "                self.trust_radius = min(2.0 * self.trust_radius, self.max_trust_radius)\n",
        "            else:\n",
        "                self.trust_radius = self.trust_radius\n",
        "\n",
        "\n",
        "        if rho > self.eta:\n",
        "            self.next = self.cur_x + shift\n",
        "        else:\n",
        "            # too close\n",
        "            self.next = self.cur_x\n",
        "\n",
        "\n",
        "    def next_point(self):\n",
        "        self.jac = MatrixSolver.findJacobian([self.func], self.cur_x, self.eps)\n",
        "        self.hess = MatrixSolver.findHessian([self.func], self.cur_x, self.eps)\n",
        "        self.trust_radius = self.initial_trust_radius\n",
        "\n",
        "        self.find_trust_radius(self.find_shift())\n"
      ],
      "metadata": {
        "id": "OYFzmIzHOZqb"
      },
      "execution_count": 1062,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussNewton(Searcher):\n",
        "\n",
        "    def calculate(self, r, x):\n",
        "        n = len(r)\n",
        "        res = np.zeros(n)\n",
        "        for i in range(n):\n",
        "          res[i] = r[i](x)\n",
        "        return res\n",
        "\n",
        "    def get_function(self, r):\n",
        "        return lambda x: self.calculate(r, x)\n",
        "\n",
        "    def __init__(self, eps, max_iteration, rs, start_x):\n",
        "        super().__init__(eps, max_iteration, self.get_function(rs), start_x)\n",
        "        self.rs = rs\n",
        "\n",
        "    def next_point(self):\n",
        "        p = MatrixSolver.pseudoInverse(MatrixSolver.findJacobian(self.rs, self.cur_x, self.eps))\n",
        "        #print(self.cur_x)\n",
        "        self.next = self.cur_x - p @ self.func(self.cur_x)"
      ],
      "metadata": {
        "id": "PYQ9xsw5VIEB"
      },
      "execution_count": 1063,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BFGS(Searcher):\n",
        "\n",
        "    def __init__(self, eps, max_iteration, func, start_x, func_grad):\n",
        "        super().__init__(eps, max_iteration, func, start_x)\n",
        "        self.func_grad = func_grad\n",
        "        self.H = np.eye(len(self.start_x), len(self.start_x))\n",
        "\n",
        "    def next_H(self, y, s):\n",
        "        I = np.eye(len(s), len(s)) # единичная матрица\n",
        "        y_t = np.transpose(y)\n",
        "        s_t = np.transpose(s)\n",
        "\n",
        "        g= 1.0/(y_t @ s)\n",
        "        g_s_y_T=g * (s @ y_t)\n",
        "        g_y_s_t=g * (y @ s_t)\n",
        "        return ((I-g_s_y_T) @ (self.H @ (I-g_y_s_t))) + g * (s @ s_t)\n",
        "\n",
        "\n",
        "    def next_point(self):\n",
        "        fgrad=MatrixSolver.grad(self.cur_x, self.func, self.eps)\n",
        "        p = -self.H @ fgrad\n",
        "\n",
        "        #находим alpha, которая подходит условиям вольфа\n",
        "        alpha = scipy.optimize.line_search(self.func, self.func_grad , self.cur_x, p, c1=1e-4, c2=0.9) # ищем коэф, удовлетворяющий условию Вольфе\n",
        "        if alpha[0] is None:\n",
        "            s = 1e-4 * p\n",
        "            print(\"None\")\n",
        "        else:\n",
        "            s = alpha[0] * p\n",
        "        \n",
        "        \n",
        "        # переход на следующую итерацию\n",
        "        self.next = self.cur_x + s\n",
        "        y=MatrixSolver.grad(self.next, self.func, self.eps)-fgrad\n",
        "        self.H = self.next_H(y, s)"
      ],
      "metadata": {
        "id": "IaRKmPZQj2vF"
      },
      "execution_count": 1064,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f1(x):\n",
        "    return sin(x[0]) + cos(x[0])\n",
        "\n",
        "start_x = [1.1]"
      ],
      "metadata": {
        "id": "2gMwukQEPo6n"
      },
      "execution_count": 1065,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dogleg"
      ],
      "metadata": {
        "id": "8MehEfkxS4fV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"from scipy.least_squares\")\n",
        "print(least_squares(f1, start_x, method=\"dogbox\", gtol=1e-5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiBeOJeWHoY-",
        "outputId": "0b8faaa6-9538-4139-c827-5de86b7a1f17"
      },
      "execution_count": 1066,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from scipy.least_squares\n",
            " active_mask: array([0])\n",
            "        cost: 4.9476925258345e-19\n",
            "         fun: array([9.947555e-10])\n",
            "        grad: array([-1.40679672e-09])\n",
            "         jac: array([[-1.41421356]])\n",
            "     message: '`gtol` termination condition is satisfied.'\n",
            "        nfev: 4\n",
            "        njev: 4\n",
            "  optimality: 1.4067967214163938e-09\n",
            "      status: 1\n",
            "     success: True\n",
            "           x: array([2.35619449])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"from lab3\")\n",
        "Dogleg(1e-5, 1000, f1, np.array(start_x, float)).run(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYOz4l-8OAXU",
        "outputId": "616b5f43-e15c-4154-8470-6527f1ce6085"
      },
      "execution_count": 1067,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from lab3\n",
            "argmin:  [[3.75891924]] \n",
            "epoches:  7 \n",
            "nfev:  14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Gauss-Newton"
      ],
      "metadata": {
        "id": "K0hnoPziUIKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def torch_f1(x):\n",
        "    return torch.sin(x[0]) + torch.cos(x[0])\n",
        "\n",
        "def f1_with_grad(x):\n",
        "    x = torch.tensor(x, requires_grad=True)\n",
        "    res = torch_f1(x)\n",
        "    res.backward()\n",
        "    return res.data.cpu().numpy(), x.grad.data.cpu().numpy()"
      ],
      "metadata": {
        "id": "F2jl9xwIfs1J"
      },
      "execution_count": 1068,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"from scipy.minimize\")\n",
        "print(minimize(f1_with_grad, start_x, method=\"Newton-CG\", jac=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4ZxgYrhT9TF",
        "outputId": "8663ea9b-c06e-4c05-b9ff-b97def6b979c"
      },
      "execution_count": 1069,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from scipy.minimize\n",
            "     fun: -1.414213562373095\n",
            "     jac: array([1.20963325e-05])\n",
            " message: 'Optimization terminated successfully.'\n",
            "    nfev: 8\n",
            "    nhev: 0\n",
            "     nit: 3\n",
            "    njev: 16\n",
            "  status: 0\n",
            " success: True\n",
            "       x: array([3.92699082])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"from lab3\")\n",
        "GaussNewton(1e-5, 1000, [f1], np.array([1.1], float)).run(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXZKQPAzT9hs",
        "outputId": "dc6e2428-2a28-46fd-9929-6d7b844753df"
      },
      "execution_count": 1070,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from lab3\n",
            "argmin:  [8.6393798] \n",
            "epoches:  7 \n",
            "nfev:  14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BFGS"
      ],
      "metadata": {
        "id": "ZhAqnl77gV84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_f1(x):\n",
        "    return cos(x[0]) - sin(x[0])"
      ],
      "metadata": {
        "id": "Nle11gRsjsiH"
      },
      "execution_count": 1071,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"from scipy.minimize\")\n",
        "print(minimize(f1_with_grad, start_x, method=\"BFGS\", jac=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAkMPDF_gZxO",
        "outputId": "689362f3-067b-4653-fba3-abdc03d63c85"
      },
      "execution_count": 1072,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from scipy.minimize\n",
            "      fun: -1.414213562373095\n",
            " hess_inv: array([[0.70712581]])\n",
            "      jac: array([5.93774474e-10])\n",
            "  message: 'Optimization terminated successfully.'\n",
            "     nfev: 8\n",
            "      nit: 4\n",
            "     njev: 8\n",
            "   status: 0\n",
            "  success: True\n",
            "        x: array([10.21017612])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"from lab3\")\n",
        "BFGS(1e-5, 1000, f1, np.array(start_x, float), grad_f1).run(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTUQWXNFiI4-",
        "outputId": "31bd6a3c-7bd8-4efc-a05d-cf4c5a6e56b3"
      },
      "execution_count": 1073,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from lab3\n",
            "argmin:  [3.92699082] \n",
            "epoches:  4 \n",
            "nfev:  8\n"
          ]
        }
      ]
    }
  ]
}